{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying to Replicate This"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_taxi_zones(df, lon_var, lat_var, locid_var):\n",
    "    \"\"\"Joins DataFrame with Taxi Zones shapefile.\n",
    "    This function takes longitude values provided by `lon_var`, and latitude\n",
    "    values provided by `lat_var` in DataFrame `df`, and performs a spatial join\n",
    "    with the NYC taxi_zones shapefile. \n",
    "    The shapefile is hard coded in, as this function makes a hard assumption of\n",
    "    latitude and longitude coordinates. It also assumes latitude=0 and \n",
    "    longitude=0 is not a datapoint that can exist in your dataset. Which is \n",
    "    reasonable for a dataset of New York, but bad for a global dataset.\n",
    "    Only rows where `df.lon_var`, `df.lat_var` are reasonably near New York,\n",
    "    and `df.locid_var` is set to np.nan are updated. \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame or dask.DataFrame\n",
    "        DataFrame containing latitudes, longitudes, and location_id columns.\n",
    "    lon_var : string\n",
    "        Name of column in `df` containing longitude values. Invalid values \n",
    "        should be np.nan.\n",
    "    lat_var : string\n",
    "        Name of column in `df` containing latitude values. Invalid values \n",
    "        should be np.nan\n",
    "    locid_var : string\n",
    "        Name of column in `df` containing taxi_zone location ids. Rows with\n",
    "        valid, nonzero values are not overwritten. \n",
    "    \"\"\"\n",
    "\n",
    "    import geopandas\n",
    "    from shapely.geometry import Point\n",
    "\n",
    "\n",
    "    localdf = df[[lon_var, lat_var, locid_var]].copy()\n",
    "    # localdf = localdf.reset_index()\n",
    "    localdf[lon_var] = localdf[lon_var].fillna(value=0.)\n",
    "    localdf[lat_var] = localdf[lat_var].fillna(value=0.)\n",
    "    localdf['replace_locid'] = (localdf[locid_var].isnull()\n",
    "                                & (localdf[lon_var] != 0.)\n",
    "                                & (localdf[lat_var] != 0.))\n",
    "\n",
    "    if (np.any(localdf['replace_locid'])):\n",
    "        shape_df = geopandas.read_file('../shapefiles/taxi_zones.shp')\n",
    "        shape_df.drop(['OBJECTID', \"Shape_Area\", \"Shape_Leng\", \"borough\", \"zone\"],\n",
    "                      axis=1, inplace=True)\n",
    "        shape_df = shape_df.to_crs({'init': 'epsg:4326'})\n",
    "\n",
    "        try:\n",
    "            local_gdf = geopandas.GeoDataFrame(\n",
    "                localdf, crs={'init': 'epsg:4326'},\n",
    "                geometry=[Point(xy) for xy in\n",
    "                          zip(localdf[lon_var], localdf[lat_var])])\n",
    "\n",
    "            local_gdf = geopandas.sjoin(\n",
    "                local_gdf, shape_df, how='left', op='within')\n",
    "\n",
    "            # one point can intersect more than one zone -- for example if on\n",
    "            # the boundary between two zones. Deduplicate by taking first valid.\n",
    "            local_gdf = local_gdf[~local_gdf.index.duplicated(keep='first')]\n",
    "\n",
    "            local_gdf.LocationID.values[~local_gdf.replace_locid] = (\n",
    "                (local_gdf[locid_var])[~local_gdf.replace_locid]).values\n",
    "\n",
    "            return local_gdf.LocationID.rename(locid_var)\n",
    "        except ValueError as ve:\n",
    "            print(ve)\n",
    "            print(ve.stacktrace())\n",
    "            return df[locid_var].astype(np.float64)\n",
    "    else:\n",
    "        return df[locid_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What I have So Far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dask_cudf\n",
    "import cuspatial\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_list = {'dropoff_datetime': 'str',  # object, # set by parse_dates in pandas read_csv\n",
    "              'dropoff_latitude': 'float64',\n",
    "              'dropoff_taxizone_id': 'float64',\n",
    "              'dropoff_longitude': 'float64',\n",
    "              'ehail_fee': 'float64',\n",
    "              'extra': 'float64',\n",
    "              'fare_amount': 'float64',\n",
    "              'improvement_surcharge': 'float64',\n",
    "              'junk1': 'str',  # object,\n",
    "              'junk2': 'str',  # object,\n",
    "              'mta_tax': 'float64',\n",
    "              'passenger_count': 'str',  # object,\n",
    "              'payment_type': 'str',  # object,\n",
    "              'pickup_datetime': 'str',  # object, # set by parse_dates in pandas read_csv\n",
    "              'pickup_latitude': 'float64',\n",
    "              'pickup_taxizone_id': 'float64',\n",
    "              'pickup_longitude': 'float64',\n",
    "              'rate_code_id': 'str',  # object,\n",
    "              'store_and_fwd_flag': 'str',  # object,\n",
    "              'tip_amount': 'float64',\n",
    "              'tolls_amount': 'float64',\n",
    "              'total_amount': 'float64',\n",
    "              'trip_distance': 'float64',\n",
    "              'trip_type': 'str',  # object,\n",
    "              'vendor_id': 'str',  # object,\n",
    "             }\n",
    "\n",
    "# make dict of paths to data directories\n",
    "relative_path = '../00_download_scripts/raw_data'\n",
    "config = {'citibike_raw_data_path': f'{relative_path}/bike/',\n",
    "          'taxi_raw_data_path': f'{relative_path}/taxi/',\n",
    "          'uber_raw_data_path': f'{relative_path}/uber/',\n",
    "          'subway_raw_data_path': f'{relative_path}/subway/',\n",
    "          'parquet_output_path': f'data/'\n",
    "         }\n",
    "\n",
    "def glob(x):\n",
    "    '''\n",
    "    Signature: sorted(glob(pathname=x, *, recursive=False))\n",
    "    Docstring:\n",
    "    Return a list of paths matching a pathname pattern.\n",
    "\n",
    "    The pattern may contain simple shell-style wildcards a la\n",
    "    fnmatch. However, unlike fnmatch, filenames starting with a\n",
    "    dot are special cases that are not matched by '*' and '?'\n",
    "    patterns.\n",
    "\n",
    "    If recursive is true, the pattern '**' will match any files and\n",
    "    zero or more directories and subdirectories.\n",
    "    '''\n",
    "    from glob import glob\n",
    "    return sorted(glob(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_green():\n",
    "    green_schema_pre_2015 = \"vendor_id,pickup_datetime,dropoff_datetime,store_and_fwd_flag,rate_code_id,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude,passenger_count,trip_distance,fare_amount,extra,mta_tax,tip_amount,tolls_amount,ehail_fee,total_amount,payment_type,trip_type,junk1,junk2\"\n",
    "    green_glob_pre_2015 = glob(\n",
    "        os.path.join(config['taxi_raw_data_path'], 'green_tripdata_201[34]*.csv'))\n",
    "\n",
    "    green_schema_2015_h1 = \"vendor_id,pickup_datetime,dropoff_datetime,store_and_fwd_flag,rate_code_id,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude,passenger_count,trip_distance,fare_amount,extra,mta_tax,tip_amount,tolls_amount,ehail_fee,improvement_surcharge,total_amount,payment_type,trip_type,junk1,junk2\"\n",
    "    green_glob_2015_h1 = glob(\n",
    "        os.path.join(config['taxi_raw_data_path'], 'green_tripdata_2015-0[1-6].csv'))\n",
    "\n",
    "    green_schema_2015_h2_2016_h1 = \"vendor_id,pickup_datetime,dropoff_datetime,store_and_fwd_flag,rate_code_id,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude,passenger_count,trip_distance,fare_amount,extra,mta_tax,tip_amount,tolls_amount,ehail_fee,improvement_surcharge,total_amount,payment_type,trip_type\"\n",
    "    green_glob_2015_h2_2016_h1 = glob(os.path.join(config['taxi_raw_data_path'], 'green_tripdata_2015-0[7-9].csv')) + glob(\n",
    "                                      os.path.join(config['taxi_raw_data_path'], 'green_tripdata_2015-1[0-2].csv')) + glob(\n",
    "                                      os.path.join(config['taxi_raw_data_path'], 'green_tripdata_2016-0[1-6].csv'))\n",
    "    \n",
    "    green_schema_2016_h2_plus = \"vendor_id,pickup_datetime,dropoff_datetime,store_and_fwd_flag,rate_code_id,pickup_taxizone_id,dropoff_taxizone_id,passenger_count,trip_distance,fare_amount,extra,mta_tax,tip_amount,tolls_amount,ehail_fee,improvement_surcharge,total_amount,payment_type,trip_type,junk1,junk2\"\n",
    "    green_glob_2016_h2_plus = glob(os.path.join(config['taxi_raw_data_path'], 'green_tripdata_2016-0[7-9].csv')) + glob(\n",
    "                                   os.path.join(config['taxi_raw_data_path'], 'green_tripdata_2016-1[0-2].csv')) + glob(\n",
    "                                   os.path.join(config['taxi_raw_data_path'], 'green_tripdata_201[7-9]*.csv'))\n",
    "\n",
    "    # Green\n",
    "    green1 = dask_cudf.read_csv(green_glob_pre_2015, \n",
    "                                header=0,\n",
    "                                na_values=[\"NA\"],\n",
    "                                parse_dates=[1, 2],\n",
    "                                infer_datetime_format=True,\n",
    "                                dtype=dtype_list,\n",
    "                                names=green_schema_pre_2015.split(','))\n",
    "    green1['dropoff_taxizone_id'] = -1.0\n",
    "    green1['pickup_taxizone_id'] = -1.0\n",
    "    green1['improvement_surcharge'] = -1.0\n",
    "    green1 = green1.drop(['junk1', 'junk2'], axis=1)\n",
    "\n",
    "    green2 = dask_cudf.read_csv(green_glob_2015_h1, \n",
    "                                header=0,\n",
    "                                na_values=[\"NA\"],\n",
    "                                parse_dates=[1, 2],\n",
    "                                infer_datetime_format=True,\n",
    "                                dtype=dtype_list,\n",
    "                                names=green_schema_2015_h1.split(','))\n",
    "    green2['dropoff_taxizone_id'] = -1.0\n",
    "    green2['pickup_taxizone_id'] = -1.0\n",
    "    green2 = green2.drop(['junk1', 'junk2'], axis=1)\n",
    "\n",
    "    green3 = dask_cudf.read_csv(green_glob_2015_h2_2016_h1, \n",
    "                                header=0,\n",
    "                                na_values=[\"NA\"],\n",
    "                                parse_dates=[1, 2],\n",
    "                                infer_datetime_format=True,\n",
    "                                dtype=dtype_list,\n",
    "                                names=green_schema_2015_h2_2016_h1.split(','))\n",
    "    green3['dropoff_taxizone_id'] = -1.0\n",
    "    green3['pickup_taxizone_id'] = -1.0\n",
    "\n",
    "    green4 = dask_cudf.read_csv(green_glob_2016_h2_plus, \n",
    "                                header=0,\n",
    "                                na_values=[\"NA\"],\n",
    "                                parse_dates=[1, 2],\n",
    "                                infer_datetime_format=True,\n",
    "                                dtype=dtype_list,\n",
    "                                names=green_schema_2016_h2_plus.split(','))\n",
    "    green4['dropoff_latitude'] = 0.0\n",
    "    green4['dropoff_longitude'] = 0.0\n",
    "    green4['pickup_latitude'] = 0.0\n",
    "    green4['pickup_longitude'] = 0.0\n",
    "    green4 = green4.drop(['junk1', 'junk2'], axis=1)\n",
    "\n",
    "    green = green1[sorted(green1.columns)].append(\n",
    "            green2[sorted(green1.columns)])\n",
    "    green = green.append(green3[sorted(green1.columns)])\n",
    "    green = green.append(green4[sorted(green1.columns)])\n",
    "\n",
    "    for field in list(green.columns):\n",
    "        if field in dtype_list:\n",
    "            green[field] = green[field].astype(dtype_list[field])\n",
    "\n",
    "    green['trip_type'] = 'green'\n",
    "\n",
    "    return green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yellow():\n",
    "    # tag file paths to data and column names by schema (x < 2015, 2015 <= x <= 2016.5, 2016.5 < x)\n",
    "    yellow_schema_pre_2015 = \"vendor_id,pickup_datetime,dropoff_datetime,passenger_count,trip_distance,pickup_longitude,pickup_latitude,rate_code_id,store_and_fwd_flag,dropoff_longitude,dropoff_latitude,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,total_amount\"\n",
    "    yellow_glob_pre_2015 = glob(os.path.join(config['taxi_raw_data_path'], 'yellow_tripdata_201[0-4]*.csv')) + glob(\n",
    "                                os.path.join(config['taxi_raw_data_path'], 'yellow_tripdata_2009*.csv'))\n",
    "    yellow_schema_2015_2016_h1 = \"vendor_id,pickup_datetime,dropoff_datetime,passenger_count,trip_distance,pickup_longitude,pickup_latitude,rate_code_id,store_and_fwd_flag,dropoff_longitude,dropoff_latitude,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount\"\n",
    "    yellow_glob_2015_2016_h1 = glob(os.path.join(config['taxi_raw_data_path'], 'yellow_tripdata_2015*.csv')) + glob(\n",
    "                                    os.path.join(config['taxi_raw_data_path'], 'yellow_tripdata_2016-0[1-6].csv'))\n",
    "    yellow_schema_2016_h2_plus = \"vendor_id,pickup_datetime,dropoff_datetime,passenger_count,trip_distance,rate_code_id,store_and_fwd_flag,pickup_taxizone_id,dropoff_taxizone_id,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount,junk1,junk2\"\n",
    "    yellow_glob_2016_h2_plus = glob(os.path.join(config['taxi_raw_data_path'], 'yellow_tripdata_2016-0[7-9].csv')) + glob(\n",
    "                                    os.path.join(config['taxi_raw_data_path'], 'yellow_tripdata_2016-1[0-2].csv')) + glob(\n",
    "                                    os.path.join(config['taxi_raw_data_path'], 'yellow_tripdata_201[7-9]*.csv'))\n",
    "\n",
    "    # create pre 2015 dataframe\n",
    "    yellow1 = dask_cudf.read_csv(yellow_glob_pre_2015, \n",
    "                                 header=0,\n",
    "                                 na_values=[\"NA\"],\n",
    "                                 parse_dates=[1, 2],\n",
    "                                 infer_datetime_format=True,\n",
    "                                 dtype=dtype_list,\n",
    "                                 names=yellow_schema_pre_2015.split(',')\n",
    "                                )\n",
    "    yellow1['dropoff_taxizone_id'] = -1.0\n",
    "    yellow1['pickup_taxizone_id'] = -1.0\n",
    "    yellow1['ehail_fee'] = np.nan\n",
    "    yellow1['improvement_surcharge'] = np.nan\n",
    "    yellow1['improvement_surcharge'] = yellow1['improvement_surcharge'].astype('float32')\n",
    "    yellow1['trip_type'] = -1.0\n",
    "    \n",
    "    # create january 2015 - june 2016 dataframe\n",
    "    yellow2 = dask_cudf.read_csv(yellow_glob_2015_2016_h1, \n",
    "                                 header=0,\n",
    "                                 na_values=[\"NA\"],\n",
    "                                 parse_dates=[1, 2],\n",
    "                                 infer_datetime_format=True,\n",
    "                                 dtype=dtype_list,\n",
    "                                 names=yellow_schema_2015_2016_h1.split(',')\n",
    "                                )\n",
    "    yellow2['dropoff_taxizone_id'] = -1.0\n",
    "    yellow2['pickup_taxizone_id'] = -1.0\n",
    "    yellow2['ehail_fee'] = np.nan\n",
    "    yellow2['trip_type'] = -1.0\n",
    "\n",
    "    # create post june 2016 dataframe\n",
    "    yellow3 = dask_cudf.read_csv(yellow_glob_2016_h2_plus, \n",
    "                                 header=0,\n",
    "                                 na_values=[\"NA\"],\n",
    "                                 parse_dates=[1, 2],\n",
    "                                 infer_datetime_format=True,\n",
    "                                 dtype=dtype_list,\n",
    "                                 names=yellow_schema_2016_h2_plus.split(',')\n",
    "                                )\n",
    "    yellow3['dropoff_latitude'] = 0.0\n",
    "    yellow3['dropoff_longitude'] = 0.0\n",
    "    yellow3['pickup_latitude'] = 0.0\n",
    "    yellow3['pickup_longitude'] = 0.0\n",
    "    yellow3['ehail_fee'] = np.nan\n",
    "    yellow3['trip_type'] = -1.0\n",
    "    yellow3 = yellow3.drop(['junk1', 'junk2'], axis=1)\n",
    "\n",
    "    # join dataframes (alphabetized column order)\n",
    "    yellow = yellow1[sorted(yellow1.columns)].append(\n",
    "             yellow2[sorted(yellow1.columns)])\n",
    "    yellow = yellow.append(yellow3[sorted(yellow1.columns)])\n",
    "\n",
    "#     yellow = dask_cudf.concat([yellow1[sorted(yellow1.columns)], \n",
    "#                                yellow2[sorted(yellow1.columns)], \n",
    "#                                yellow3[sorted(yellow1.columns)]]\n",
    "#                              )\n",
    "                     \n",
    "    for field in list(yellow.columns):\n",
    "        if field in dtype_list:\n",
    "            yellow[field] = yellow[field].astype(dtype_list[field])\n",
    "\n",
    "    yellow['trip_type'] = 'yellow'\n",
    "\n",
    "    return yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber():\n",
    "    uber_schema_2014 = \"pickup_datetime,pickup_latitude,pickup_longitude,junk1\"\n",
    "    uber_glob_2014 = glob(os.path.join(config['uber_raw_data_path'],'uber*-???14.csv'))\n",
    "\n",
    "    uber1 = dask_cudf.read_csv(uber_glob_2014, \n",
    "                               header=0,\n",
    "                               na_values=[\"NA\"], \n",
    "                               parse_dates=[0,],\n",
    "                               infer_datetime_format = True,\n",
    "                               dtype=dtype_list,\n",
    "                               names=uber_schema_2014.split(',')\n",
    "                              )\n",
    "    uber1 = uber1.drop(['junk1',], axis=1)\n",
    "    uber1 = uber1.assign(pickup_taxizone_id=-1.0)\n",
    "\n",
    "    uber_schema_2015 = \"junk1,pickup_datetime,junk2,pickup_taxizone_id\"\n",
    "    uber_glob_2015 = glob(os.path.join(config['uber_raw_data_path'],'uber*15.csv'))\n",
    "\n",
    "    uber2 = dask_cudf.read_csv(uber_glob_2015, \n",
    "                        header=0,\n",
    "                        na_values=[\"NA\"], \n",
    "                        parse_dates=[1,],\n",
    "                        infer_datetime_format = True,\n",
    "                        dtype=dtype_list,\n",
    "                        names=uber_schema_2015.split(',')\n",
    "                       )\n",
    "    uber2 = uber2.drop(['junk1', 'junk2'], axis=1)\n",
    "    uber2 = uber2.assign(pickup_latitude=0.0, pickup_longitude=0.0)\n",
    "\n",
    "    \n",
    "    uberdf = dask_cudf.concat([uber1[sorted(uber1.columns)], \n",
    "                               uber2[sorted(uber1.columns)]])\n",
    "\n",
    "#     default_values = {np.float64: np.nan, np.int64: -999, object: \"\"}\n",
    "\n",
    "    for field in dtype_list:\n",
    "        if (field in uberdf.columns):\n",
    "            uberdf[field] = uberdf[field].astype(dtype_list[field])\n",
    "        elif field == 'pickup_datetime':\n",
    "            pass\n",
    "        else:\n",
    "            uberdf[field] = np.nan\n",
    "            uberdf[field] = uberdf[field].astype(dtype_list[field])\n",
    "    #         uberdf = uberdf.assign(**{field: default_values[dtype_list[field]]})\n",
    "\n",
    "\n",
    "    uberdf = uberdf.drop(['junk1', 'junk2'], axis=1)\n",
    "\n",
    "#     uberdf['dropoff_datetime'] = np.datetime64(\"1970-01-01 00:00:00\")\n",
    "    #uberdf = uberdf.repartition(npartitions=20)\n",
    "\n",
    "    uberdf['trip_type'] = 'uber'\n",
    "\n",
    "    uberdf = uberdf[sorted(uberdf.columns)]\n",
    "\n",
    "    return uberdf\n",
    "\n",
    "\n",
    "# %%time\n",
    "# get_uber().compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "green = get_green()\n",
    "yellow = get_yellow()\n",
    "uber = get_uber()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dask_cudf.core.DataFrame"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_trips = uber.append(green).append(yellow)\n",
    "type(all_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.99 s, sys: 487 ms, total: 3.48 s\n",
      "Wall time: 3.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = all_trips.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING: 70.9256%\n",
      "IDK WHY: 70.2762%\n"
     ]
    }
   ],
   "source": [
    "missing_pickup_taxizone_ids = (len(df.loc[df.pickup_taxizone_id == -1])/len(df))*100\n",
    "unexpected_missing_pickup_taxizone_ids = (len(df.loc[(df.pickup_taxizone_id == -1) & (df.pickup_latitude != 0) & (df.pickup_longitude != 0)])/len(df))*100\n",
    "\n",
    "print(f'MISSING: {str(missing_pickup_taxizone_ids)[:7]}%\\nIDK WHY: {str(unexpected_missing_pickup_taxizone_ids)[:7]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0      1707623\n",
       " 74.0       20472\n",
       " 75.0       20120\n",
       " 41.0       18125\n",
       " 7.0        15255\n",
       "           ...   \n",
       " 187.0          3\n",
       " 245.0          2\n",
       " 30.0           1\n",
       " 172.0          1\n",
       " 176.0          1\n",
       "Name: pickup_taxizone_id, Length: 253, dtype: int32"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pickup_taxizone_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0      1107623\n",
       " NaN       700000\n",
       " 236.0      17076\n",
       " 237.0      12967\n",
       " 74.0       12588\n",
       "           ...   \n",
       " 204.0          5\n",
       " 44.0           4\n",
       " 30.0           3\n",
       " 2.0            2\n",
       " 176.0          2\n",
       "Name: dropoff_taxizone_id, Length: 261, dtype: int32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropoff_taxizone_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_trips.compute().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# all_trips.pickup_datetime.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (len(all_trips.loc[(all_trips.dropoff_taxizone_id == -1) & (all_trips.dropoff_latitude != 0)].compute())/len(all_trips.compute()))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (len(all_trips.loc[(all_trips.pickup_taxizone_id == -1) & (all_trips.pickup_latitude != 0)].compute())/len(all_trips.compute()))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(all_trips.loc[(all_trips.dropoff_taxizone_id == -1) & (all_trips.dropoff_datetime > '2016-01-01 00:00:00')].compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(all_trips.loc[(all_trips.dropoff_taxizone_id == 161) & (all_trips.dropoff_datetime > '2017-01-01 00:00:00')].compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(all_trips.loc[(all_trips.dropoff_taxizone_id == 161) & (all_trips.dropoff_datetime > '2016-01-01 00:00:00')].compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(all_trips.loc[(all_trips.dropoff_taxizone_id == 183) & (all_trips.dropoff_datetime > '2016-01-01 00:00:00')].compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(all_trips.loc[(all_trips.dropoff_taxizone_id == 185) & (all_trips.dropoff_datetime > '2017-01-01 00:00:00')].compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(all_trips.loc[(all_trips.dropoff_taxizone_id == 185) & (all_trips.dropoff_datetime > '2016-01-01 00:00:00')].compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(all_trips.loc[(all_trips.dropoff_taxizone_id == 200) & (all_trips.dropoff_datetime > '2016-01-01 00:00:00')].compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_iterations = list(np.arange(0, 263, 31))\n",
    "pip_iterations.append(263)\n",
    "\n",
    "taxi_zones = cuspatial.read_polygon_shapefile('zones/cu_taxi_zones.shp')\n",
    "\n",
    "def assign_taxi_zones(df, lon_var, lat_var, locid_var):\n",
    "    \"\"\"\n",
    "    Derives Taxi Zones from shapefile.\n",
    "    \n",
    "    This function takes longitude values provided by `lon_var`, and latitude\n",
    "    values provided by `lat_var` in DataFrame `df`, and performs a spatial join\n",
    "    with the NYC taxi_zones shapefile. \n",
    "    \n",
    "    The shapefile is hard coded in, as this function makes a hard assumption of\n",
    "    latitude and longitude coordinates. It also assumes latitude=0.0 and \n",
    "    longitude=0.0 is not a datapoint that can exist in your dataset. Which is \n",
    "    reasonable for a dataset of New York, but a bit edgy for a global dataset.\n",
    "    \n",
    "    Only rows where `df.lon_var`, `df.lat_var` are reasonably near New York,\n",
    "    and `df.locid_var` is set to -1.0 are updated.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : cudf.DataFrame or dask_cudf.DataFrame\n",
    "        DataFrame containing latitudes, longitudes, and location_id columns.\n",
    "    lon_var : string\n",
    "        Name of column in `df` containing longitude values. Invalid values \n",
    "        should be -1.0.\n",
    "    lat_var : string\n",
    "        Name of column in `df` containing latitude values. Invalid values \n",
    "        should be -1.0\n",
    "    locid_var : string\n",
    "        Name of column in `df` containing taxi_zone location ids. Rows with\n",
    "        valid, nonzero values are not overwritten.\n",
    "        \"\"\"\n",
    "    # focus location columns\n",
    "    localdf = df[[lon_var, lat_var, locid_var]].copy()\n",
    "    # localdf = localdf.reset_index()\n",
    "    \n",
    "    # fill missing lat/long values\n",
    "    localdf[lon_var] = localdf[lon_var].fillna(value=0.0)\n",
    "    localdf[lat_var] = localdf[lat_var].fillna(value=0.0)\n",
    "    \n",
    "    # (bool column) is location id missing && do we have lat/long coordinates?\n",
    "    localdf['replace_locid'] = ((localdf[locid_var] == -1.0)\n",
    "                                & (localdf[lon_var] != 0.0)\n",
    "                                & (localdf[lat_var] != 0.0)\n",
    "                               )\n",
    "    c = 0\n",
    "    # are there any values to replace?\n",
    "    if (np.any(localdf['replace_locid'])):  # makes ~28.469% faster\n",
    "        # go through zones 31 at a time\n",
    "        for i in range(len(pip_iterations)-1):\n",
    "            # tag 1st and last zone #s\n",
    "            start = pip_iterations[i]\n",
    "            end = pip_iterations[i+1]\n",
    "            # derive taxi zones from coordinates\n",
    "            t_zones = cuspatial.point_in_polygon(localdf[lon_var], \n",
    "                                                 localdf[lat_var], \n",
    "                                                 taxi_zones[0][start:end], \n",
    "                                                 taxi_zones[1], \n",
    "                                                 taxi_zones[2]['x'], \n",
    "                                                 taxi_zones[2]['y'])\n",
    "            # insert taxi zones into location id columns \n",
    "            for j in t_zones.columns:\n",
    "#                 if j == 200:\n",
    "#                     print(f'j == {j}')\n",
    "#                     print(f'np.sum(t_zones[j]) == {np.sum(t_zones[j])}')\n",
    "#                     print(localdf[locid_var].loc[t_zones[j]].value_counts())\n",
    "                localdf[locid_var].loc[t_zones[j]] = j\n",
    "#                 if j == 200:\n",
    "#                     print(localdf[locid_var].loc[t_zones[j]].value_counts())\n",
    "#                     print()\n",
    "#                     print(c)\n",
    "#                     c += 1\n",
    "#                     print()\n",
    "#                     print()\n",
    "            \n",
    "        return localdf[locid_var].astype('float64') \n",
    "\n",
    "    else:\n",
    "        localdf[locid_var] = localdf[locid_var].astype('float64')   \n",
    "        return localdf[locid_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_trips = get_uber()\n",
    "\n",
    "# derive & assign pickup & dropoff taxi zones \n",
    "all_trips['dropoff_taxizone_id'] = all_trips.map_partitions(assign_taxi_zones, \n",
    "                                                            lon_var='dropoff_longitude', \n",
    "                                                            lat_var='dropoff_latitude',\n",
    "                                                            locid_var='dropoff_taxizone_id', \n",
    "                                                            meta=('dropoff_taxizone_id', np.float64))\n",
    "all_trips['pickup_taxizone_id'] = all_trips.map_partitions(assign_taxi_zones, \n",
    "                                                           lon_var='pickup_longitude', \n",
    "                                                           lat_var='pickup_latitude',\n",
    "                                                           locid_var='pickup_taxizone_id', \n",
    "                                                           meta=('pickup_taxizone_id', np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_trips = all_trips[sorted(all_trips.columns)]\n",
    "# all_trips = all_trips.repartition(npartitions=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trips = all_trips.map_partitions(lambda x: x.sort_values('pickup_datetime'), \n",
    "                                     meta=all_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.7 s, sys: 14.1 s, total: 56.8 s\n",
      "Wall time: 56.9 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_taxizone_id</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>extra</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>...</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_taxizone_id</th>\n",
       "      <th>rate_code_id</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>vendor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68772</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.9952</td>\n",
       "      <td>147.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uber</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85237</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.9874</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uber</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83557</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.0041</td>\n",
       "      <td>230.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uber</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96581</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.9873</td>\n",
       "      <td>100.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uber</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49440</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.9922</td>\n",
       "      <td>151.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uber</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30398</th>\n",
       "      <td>2019-02-01 00:01:39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.14</td>\n",
       "      <td>0.99</td>\n",
       "      <td>yellow</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>2019-02-01 00:02:52</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.15</td>\n",
       "      <td>0.50</td>\n",
       "      <td>yellow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96017</th>\n",
       "      <td>2019-02-01 00:11:38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>164.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.30</td>\n",
       "      <td>0.80</td>\n",
       "      <td>yellow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87599</th>\n",
       "      <td>2019-02-01 00:08:20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.19</td>\n",
       "      <td>0.68</td>\n",
       "      <td>yellow</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67751</th>\n",
       "      <td>2019-07-23 01:51:51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>234.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>14.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.96</td>\n",
       "      <td>3.13</td>\n",
       "      <td>yellow</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2407623 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          dropoff_datetime dropoff_latitude dropoff_longitude  \\\n",
       "68772                  NaN              NaN               NaN   \n",
       "85237                  NaN              NaN               NaN   \n",
       "83557                  NaN              NaN               NaN   \n",
       "96581                  NaN              NaN               NaN   \n",
       "49440                  NaN              NaN               NaN   \n",
       "...                    ...              ...               ...   \n",
       "30398  2019-02-01 00:01:39              0.0               0.0   \n",
       "3419   2019-02-01 00:02:52              0.0               0.0   \n",
       "96017  2019-02-01 00:11:38              0.0               0.0   \n",
       "87599  2019-02-01 00:08:20              0.0               0.0   \n",
       "67751  2019-07-23 01:51:51              0.0               0.0   \n",
       "\n",
       "       dropoff_taxizone_id ehail_fee  extra  fare_amount  \\\n",
       "68772                  NaN       NaN    NaN          NaN   \n",
       "85237                  NaN       NaN    NaN          NaN   \n",
       "83557                  NaN       NaN    NaN          NaN   \n",
       "96581                  NaN       NaN    NaN          NaN   \n",
       "49440                  NaN       NaN    NaN          NaN   \n",
       "...                    ...       ...    ...          ...   \n",
       "30398                 48.0       NaN    0.5          6.5   \n",
       "3419                 237.0       NaN    0.5          5.5   \n",
       "96017                164.0       NaN    0.5          9.0   \n",
       "87599                 68.0       NaN    0.5          5.0   \n",
       "67751                234.0       NaN    0.5         14.5   \n",
       "\n",
       "       improvement_surcharge  mta_tax passenger_count  ... pickup_longitude  \\\n",
       "68772                    NaN      NaN             NaN  ...         -73.9952   \n",
       "85237                    NaN      NaN             NaN  ...         -73.9874   \n",
       "83557                    NaN      NaN             NaN  ...         -74.0041   \n",
       "96581                    NaN      NaN             NaN  ...         -73.9873   \n",
       "49440                    NaN      NaN             NaN  ...         -73.9922   \n",
       "...                      ...      ...             ...  ...              ...   \n",
       "30398                    0.3      0.5               1  ...           0.0000   \n",
       "3419                     0.3      0.5               1  ...           0.0000   \n",
       "96017                    0.3      0.5               2  ...           0.0000   \n",
       "87599                    0.3      0.5               1  ...           0.0000   \n",
       "67751                    0.3      0.5               1  ...           0.0000   \n",
       "\n",
       "       pickup_taxizone_id  rate_code_id store_and_fwd_flag tip_amount  \\\n",
       "68772               147.0           NaN                NaN        NaN   \n",
       "85237               100.0           NaN                NaN        NaN   \n",
       "83557               230.0           NaN                NaN        NaN   \n",
       "96581               100.0           NaN                NaN        NaN   \n",
       "49440               151.0           NaN                NaN        NaN   \n",
       "...                   ...           ...                ...        ...   \n",
       "30398               100.0             1                  N       2.34   \n",
       "3419                140.0             1                  N       1.35   \n",
       "96017                68.0             1                  N       0.00   \n",
       "87599               100.0             1                  N       1.89   \n",
       "67751               148.0             1                  N       3.16   \n",
       "\n",
       "       tolls_amount  total_amount  trip_distance  trip_type vendor_id  \n",
       "68772           NaN           NaN            NaN       uber       NaN  \n",
       "85237           NaN           NaN            NaN       uber       NaN  \n",
       "83557           NaN           NaN            NaN       uber       NaN  \n",
       "96581           NaN           NaN            NaN       uber       NaN  \n",
       "49440           NaN           NaN            NaN       uber       NaN  \n",
       "...             ...           ...            ...        ...       ...  \n",
       "30398           0.0         10.14           0.99     yellow         2  \n",
       "3419            0.0          8.15           0.50     yellow         1  \n",
       "96017           0.0         10.30           0.80     yellow         1  \n",
       "87599           0.0          8.19           0.68     yellow         2  \n",
       "67751           0.0         18.96           3.13     yellow         2  \n",
       "\n",
       "[2407623 rows x 23 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "df = all_trips.compute()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISSING: 1.25866%\n",
      "IDK WHY: 0.60919%\n"
     ]
    }
   ],
   "source": [
    "missing_pickup_taxizone_ids = (len(df.loc[df.pickup_taxizone_id == -1])/len(df))*100\n",
    "unexpected_missing_pickup_taxizone_ids = (len(df.loc[(df.pickup_taxizone_id == -1) & (df.pickup_latitude != 0) & (df.pickup_longitude != 0)])/len(df))*100\n",
    "\n",
    "print(f'MISSING: {str(missing_pickup_taxizone_ids)[:7]}%\\nIDK WHY: {str(unexpected_missing_pickup_taxizone_ids)[:7]}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "234.0    58579\n",
       "237.0    58203\n",
       "161.0    55542\n",
       "160.0    53019\n",
       "236.0    52423\n",
       "         ...  \n",
       "105.0        3\n",
       "99.0         1\n",
       "103.0        1\n",
       "104.0        1\n",
       "109.0        1\n",
       "Name: pickup_taxizone_id, Length: 266, dtype: int32"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.pickup_taxizone_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN      700000\n",
       "236.0     49084\n",
       "237.0     41530\n",
       "161.0     37885\n",
       "160.0     33646\n",
       "          ...  \n",
       "172.0        19\n",
       "109.0        18\n",
       "199.0         8\n",
       "105.0         2\n",
       "99.0          1\n",
       "Name: dropoff_taxizone_id, Length: 265, dtype: int32"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dropoff_taxizone_id.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30304"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[df.pickup_taxizone_id == -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2407623"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.491522136148392"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df.loc[(df.pickup_taxizone_id == -1) & (df.pickup_datetime > '2019-01-01 00:00:00')])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.491522136148392"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df.loc[(df.pickup_taxizone_id == -1) & (df.pickup_datetime > '2018-01-01 00:00:00')])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.491522136148392"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df.loc[(df.pickup_taxizone_id == -1) \n",
    "            & (df.pickup_latitude != 0) \n",
    "            & (df.pickup_longitude != 0) \n",
    "            & (df.pickup_datetime > '2018-01-01 00:00:00')])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.491522136148392"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df.loc[(df.pickup_taxizone_id == -1) & (df.pickup_datetime > '2017-01-01 00:00:00')])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5736363209688561"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df.loc[(df.pickup_taxizone_id == -1) & (df.pickup_datetime > '2016-01-01 00:00:00')])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6694154358884261"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df.loc[(df.pickup_taxizone_id == -1) & (df.pickup_datetime > '2015-01-01 00:00:00')])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5056439484088664"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df.loc[(df.pickup_taxizone_id == -1) \n",
    "            & (df.pickup_latitude != 0) \n",
    "            & (df.pickup_longitude != 0) \n",
    "            & (df.pickup_datetime > '2015-01-01 00:00:00')])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7432226723203758"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df.loc[(df.pickup_taxizone_id == -1) & (df.pickup_datetime > '2014-01-01 00:00:00')])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8475994788220581"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df.loc[(df.pickup_taxizone_id == -1) & (df.pickup_datetime > '2013-01-01 00:00:00')])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5224239841536652"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df.loc[(df.pickup_taxizone_id == -1) \n",
    "            & (df.pickup_latitude != 0) \n",
    "            & (df.pickup_longitude != 0) \n",
    "            & (df.pickup_datetime > '2013-01-01 00:00:00')])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9558390163243996"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df.loc[(df.pickup_taxizone_id == -1) & (df.pickup_datetime > '2012-01-01 00:00:00')])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.072842384376624"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df.loc[(df.pickup_taxizone_id == -1) & (df.pickup_datetime > '2011-01-01 00:00:00')])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1670847138443188"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df.loc[(df.pickup_taxizone_id == -1) & (df.pickup_datetime > '2010-01-01 00:00:00')])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5821094083251407"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df.loc[(df.pickup_taxizone_id == -1) \n",
    "            & (df.pickup_latitude != 0) \n",
    "            & (df.pickup_longitude != 0) \n",
    "            & (df.pickup_datetime > '2010-01-01 00:00:00')])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.258668819827689"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df.loc[(df.pickup_taxizone_id == -1) & (df.pickup_datetime > '2009-01-01 00:00:00')])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6091900600716973"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df.loc[(df.pickup_taxizone_id == -1) \n",
    "            & (df.pickup_latitude != 0) \n",
    "            & (df.pickup_longitude != 0) \n",
    "            & (df.pickup_datetime > '2009-01-01 00:00:00')])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[(df.dropoff_taxizone_id == -1) & (df.dropoff_datetime > '2016-01-01 00:00:00') & (df.dropoff_latitude != 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4470"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[(df.dropoff_taxizone_id == -1) & (df.dropoff_latitude != 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18428964999919006"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df.loc[(df.dropoff_taxizone_id == -1) & (df.dropoff_longitude != 0)])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14705"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df.loc[(df.pickup_taxizone_id == -1) & (df.pickup_latitude != 0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6092315948136399"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(len(df.loc[(df.pickup_taxizone_id == -1) & (df.pickup_longitude != 0)])/len(df))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_taxizone_id</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>extra</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>...</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_taxizone_id</th>\n",
       "      <th>rate_code_id</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>vendor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>80052</th>\n",
       "      <td>2016-01-01 00:23:30</td>\n",
       "      <td>40.724758</td>\n",
       "      <td>-74.073868</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.073845</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>70.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>green</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12110</th>\n",
       "      <td>2016-01-02 00:31:01</td>\n",
       "      <td>40.707867</td>\n",
       "      <td>-73.998917</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>11.50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.954536</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12.80</td>\n",
       "      <td>2.79</td>\n",
       "      <td>green</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48660</th>\n",
       "      <td>2016-01-01 02:18:10</td>\n",
       "      <td>41.169556</td>\n",
       "      <td>-73.254982</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>222.50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.990753</td>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5.54</td>\n",
       "      <td>229.34</td>\n",
       "      <td>53.27</td>\n",
       "      <td>green</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11179</th>\n",
       "      <td>2016-01-01 01:32:42</td>\n",
       "      <td>40.919346</td>\n",
       "      <td>-73.866753</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.936562</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>25.30</td>\n",
       "      <td>8.60</td>\n",
       "      <td>green</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67437</th>\n",
       "      <td>2016-01-01 03:39:15</td>\n",
       "      <td>40.940136</td>\n",
       "      <td>-73.897469</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>17.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.885063</td>\n",
       "      <td>174.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>5.49</td>\n",
       "      <td>0.00</td>\n",
       "      <td>23.79</td>\n",
       "      <td>5.52</td>\n",
       "      <td>green</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43990</th>\n",
       "      <td>2016-01-31 07:20:03</td>\n",
       "      <td>40.906124</td>\n",
       "      <td>-73.838425</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.983582</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>57.30</td>\n",
       "      <td>20.10</td>\n",
       "      <td>yellow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64280</th>\n",
       "      <td>2016-01-31 07:42:54</td>\n",
       "      <td>40.631008</td>\n",
       "      <td>-73.719086</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.781784</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>5.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27.25</td>\n",
       "      <td>6.81</td>\n",
       "      <td>yellow</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58588</th>\n",
       "      <td>2016-01-31 09:06:29</td>\n",
       "      <td>40.479477</td>\n",
       "      <td>-74.406914</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>232.74</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.406914</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>233.04</td>\n",
       "      <td>0.00</td>\n",
       "      <td>yellow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77308</th>\n",
       "      <td>2016-01-31 10:58:40</td>\n",
       "      <td>40.535858</td>\n",
       "      <td>-74.534012</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>300.00</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.801193</td>\n",
       "      <td>215.0</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21.58</td>\n",
       "      <td>321.88</td>\n",
       "      <td>55.48</td>\n",
       "      <td>yellow</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59189</th>\n",
       "      <td>2016-01-31 14:07:51</td>\n",
       "      <td>40.787479</td>\n",
       "      <td>-73.645317</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>60.50</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.781792</td>\n",
       "      <td>136.0</td>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>61.30</td>\n",
       "      <td>17.94</td>\n",
       "      <td>yellow</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>538 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          dropoff_datetime  dropoff_latitude  dropoff_longitude  \\\n",
       "80052  2016-01-01 00:23:30         40.724758         -74.073868   \n",
       "12110  2016-01-02 00:31:01         40.707867         -73.998917   \n",
       "48660  2016-01-01 02:18:10         41.169556         -73.254982   \n",
       "11179  2016-01-01 01:32:42         40.919346         -73.866753   \n",
       "67437  2016-01-01 03:39:15         40.940136         -73.897469   \n",
       "...                    ...               ...                ...   \n",
       "43990  2016-01-31 07:20:03         40.906124         -73.838425   \n",
       "64280  2016-01-31 07:42:54         40.631008         -73.719086   \n",
       "58588  2016-01-31 09:06:29         40.479477         -74.406914   \n",
       "77308  2016-01-31 10:58:40         40.535858         -74.534012   \n",
       "59189  2016-01-31 14:07:51         40.787479         -73.645317   \n",
       "\n",
       "       dropoff_taxizone_id  ehail_fee  extra  fare_amount  \\\n",
       "80052                 -1.0       -1.0    0.0        70.00   \n",
       "12110                 -1.0       -1.0    0.5        11.50   \n",
       "48660                 -1.0       -1.0    0.5       222.50   \n",
       "11179                 -1.0       -1.0    0.5        24.00   \n",
       "67437                 -1.0       -1.0    0.5        17.00   \n",
       "...                    ...        ...    ...          ...   \n",
       "43990                 -1.0        NaN    0.0        56.50   \n",
       "64280                 -1.0        NaN    0.0        21.00   \n",
       "58588                 -1.0        NaN    0.0       232.74   \n",
       "77308                 -1.0        NaN    0.0       300.00   \n",
       "59189                 -1.0        NaN    0.0        60.50   \n",
       "\n",
       "       improvement_surcharge  mta_tax passenger_count  ... pickup_longitude  \\\n",
       "80052                    0.0      0.0               1  ...       -74.073845   \n",
       "12110                    0.3      0.5               1  ...       -73.954536   \n",
       "48660                    0.3      0.5               1  ...       -73.990753   \n",
       "11179                    0.3      0.5               1  ...       -73.936562   \n",
       "67437                    0.3      0.5               1  ...       -73.885063   \n",
       "...                      ...      ...             ...  ...              ...   \n",
       "43990                    0.3      0.5               2  ...       -73.983582   \n",
       "64280                    0.3      0.5               1  ...       -73.781784   \n",
       "58588                    0.3      0.0               1  ...       -74.406914   \n",
       "77308                    0.3      0.0               1  ...       -73.801193   \n",
       "59189                    0.3      0.5               1  ...       -73.781792   \n",
       "\n",
       "       pickup_taxizone_id  rate_code_id store_and_fwd_flag tip_amount  \\\n",
       "80052                -1.0             5                  N       0.00   \n",
       "12110                21.0             1                  N       0.00   \n",
       "48660                28.0             4                  N       0.00   \n",
       "11179                43.0             1                  N       0.00   \n",
       "67437               174.0             1                  N       5.49   \n",
       "...                   ...           ...                ...        ...   \n",
       "43990                47.0             1                  N       0.00   \n",
       "64280               136.0             1                  N       5.45   \n",
       "58588                -1.0             5                  N       0.00   \n",
       "77308               215.0             5                  N       0.00   \n",
       "59189               136.0             4                  N       0.00   \n",
       "\n",
       "       tolls_amount  total_amount  trip_distance  trip_type vendor_id  \n",
       "80052          0.00         70.00           0.00      green         2  \n",
       "12110          0.00         12.80           2.79      green         2  \n",
       "48660          5.54        229.34          53.27      green         2  \n",
       "11179          0.00         25.30           8.60      green         1  \n",
       "67437          0.00         23.79           5.52      green         2  \n",
       "...             ...           ...            ...        ...       ...  \n",
       "43990          0.00         57.30          20.10     yellow         1  \n",
       "64280          0.00         27.25           6.81     yellow         2  \n",
       "58588          0.00        233.04           0.00     yellow         1  \n",
       "77308         21.58        321.88          55.48     yellow         2  \n",
       "59189          0.00         61.30          17.94     yellow         2  \n",
       "\n",
       "[538 rows x 23 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df.dropoff_taxizone_id == -1) & (df.dropoff_datetime > '2016-01-01 00:00:00') & (df.dropoff_latitude != 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.loc[df.dropoff_taxizone_id == -1].head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAPIDS Stable",
   "language": "python",
   "name": "rapids-stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
