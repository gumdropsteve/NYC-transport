{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert Taxi to Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dask_cudf\n",
    "import cuspatial\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_list = {'dropoff_datetime': 'str', \n",
    "              'dropoff_latitude': 'float64',\n",
    "              'dropoff_taxizone_id': 'float64',\n",
    "              'dropoff_longitude': 'float64',\n",
    "              'ehail_fee': 'float64',\n",
    "              'extra': 'float64',\n",
    "              'fare_amount': 'float64',\n",
    "              'improvement_surcharge': 'float64',\n",
    "              'junk1': 'str',\n",
    "              'junk2': 'str',\n",
    "              'mta_tax': 'float64',\n",
    "              'passenger_count': 'str', \n",
    "              'payment_type': 'str', \n",
    "              'pickup_datetime': 'str',  \n",
    "              'pickup_latitude': 'float64',\n",
    "              'pickup_taxizone_id': 'float64',\n",
    "              'pickup_longitude': 'float64',\n",
    "              'rate_code_id': 'str', \n",
    "              'store_and_fwd_flag': 'str', \n",
    "              'tip_amount': 'float64',\n",
    "              'tolls_amount': 'float64',\n",
    "              'total_amount': 'float64',\n",
    "              'trip_distance': 'float64',\n",
    "              'trip_type': 'str', \n",
    "              'vendor_id': 'str',  \n",
    "             }\n",
    "\n",
    "# make dict of paths to data directories\n",
    "relative_path = '../00_download_scripts/raw_data'\n",
    "config = {'citibike_raw_data_path': f'{relative_path}/bike/',\n",
    "          'taxi_raw_data_path': f'{relative_path}/taxi/',\n",
    "          'uber_raw_data_path': f'{relative_path}/uber/',\n",
    "          'subway_raw_data_path': f'{relative_path}/subway/',\n",
    "          'parquet_output_path': f'data/'\n",
    "         }\n",
    "\n",
    "def glob(x):\n",
    "    '''\n",
    "    Signature: sorted(glob(pathname=x, *, recursive=False))\n",
    "    Docstring:\n",
    "    Return a list of paths matching a pathname pattern.\n",
    "\n",
    "    The pattern may contain simple shell-style wildcards a la\n",
    "    fnmatch. However, unlike fnmatch, filenames starting with a\n",
    "    dot are special cases that are not matched by '*' and '?'\n",
    "    patterns.\n",
    "\n",
    "    If recursive is true, the pattern '**' will match any files and\n",
    "    zero or more directories and subdirectories.\n",
    "    '''\n",
    "    from glob import glob\n",
    "    return sorted(glob(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_green():\n",
    "    green_schema_pre_2015 = \"vendor_id,pickup_datetime,dropoff_datetime,store_and_fwd_flag,rate_code_id,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude,passenger_count,trip_distance,fare_amount,extra,mta_tax,tip_amount,tolls_amount,ehail_fee,total_amount,payment_type,trip_type,junk1,junk2\"\n",
    "    green_glob_pre_2015 = glob(\n",
    "        os.path.join(config['taxi_raw_data_path'], 'green_tripdata_201[34]*.csv'))\n",
    "\n",
    "    green_schema_2015_h1 = \"vendor_id,pickup_datetime,dropoff_datetime,store_and_fwd_flag,rate_code_id,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude,passenger_count,trip_distance,fare_amount,extra,mta_tax,tip_amount,tolls_amount,ehail_fee,improvement_surcharge,total_amount,payment_type,trip_type,junk1,junk2\"\n",
    "    green_glob_2015_h1 = glob(\n",
    "        os.path.join(config['taxi_raw_data_path'], 'green_tripdata_2015-0[1-6].csv'))\n",
    "\n",
    "    green_schema_2015_h2_2016_h1 = \"vendor_id,pickup_datetime,dropoff_datetime,store_and_fwd_flag,rate_code_id,pickup_longitude,pickup_latitude,dropoff_longitude,dropoff_latitude,passenger_count,trip_distance,fare_amount,extra,mta_tax,tip_amount,tolls_amount,ehail_fee,improvement_surcharge,total_amount,payment_type,trip_type\"\n",
    "    green_glob_2015_h2_2016_h1 = glob(os.path.join(config['taxi_raw_data_path'], 'green_tripdata_2015-0[7-9].csv')) + glob(\n",
    "                                      os.path.join(config['taxi_raw_data_path'], 'green_tripdata_2015-1[0-2].csv')) + glob(\n",
    "                                      os.path.join(config['taxi_raw_data_path'], 'green_tripdata_2016-0[1-6].csv'))\n",
    "    \n",
    "    green_schema_2016_h2_plus = \"vendor_id,pickup_datetime,dropoff_datetime,store_and_fwd_flag,rate_code_id,pickup_taxizone_id,dropoff_taxizone_id,passenger_count,trip_distance,fare_amount,extra,mta_tax,tip_amount,tolls_amount,ehail_fee,improvement_surcharge,total_amount,payment_type,trip_type,junk1,junk2\"\n",
    "    green_glob_2016_h2_plus = glob(os.path.join(config['taxi_raw_data_path'], 'green_tripdata_2016-0[7-9].csv')) + glob(\n",
    "                                   os.path.join(config['taxi_raw_data_path'], 'green_tripdata_2016-1[0-2].csv')) + glob(\n",
    "                                   os.path.join(config['taxi_raw_data_path'], 'green_tripdata_201[7-9]*.csv'))\n",
    "\n",
    "    # before 2015 dataframe\n",
    "    green1 = dask_cudf.read_csv(green_glob_pre_2015, \n",
    "                                header=0,\n",
    "                                na_values=[\"NA\"],\n",
    "                                parse_dates=[1, 2],\n",
    "                                infer_datetime_format=True,\n",
    "                                dtype=dtype_list,\n",
    "                                names=green_schema_pre_2015.split(','))\n",
    "    green1['dropoff_taxizone_id'] = -1.0\n",
    "    green1['pickup_taxizone_id'] = -1.0\n",
    "    green1['improvement_surcharge'] = np.nan\n",
    "    green1 = green1.drop(['junk1', 'junk2'], axis=1)\n",
    "\n",
    "    # january 2015 - june 2015 dataframe\n",
    "    green2 = dask_cudf.read_csv(green_glob_2015_h1, \n",
    "                                header=0,\n",
    "                                na_values=[\"NA\"],\n",
    "                                parse_dates=[1, 2],\n",
    "                                infer_datetime_format=True,\n",
    "                                dtype=dtype_list,\n",
    "                                names=green_schema_2015_h1.split(','))\n",
    "    green2['dropoff_taxizone_id'] = -1.0\n",
    "    green2['pickup_taxizone_id'] = -1.0\n",
    "    green2 = green2.drop(['junk1', 'junk2'], axis=1)\n",
    "\n",
    "    # july 2015 - june 2016 dataframe\n",
    "    green3 = dask_cudf.read_csv(green_glob_2015_h2_2016_h1, \n",
    "                                header=0,\n",
    "                                na_values=[\"NA\"],\n",
    "                                parse_dates=[1, 2],\n",
    "                                infer_datetime_format=True,\n",
    "                                dtype=dtype_list,\n",
    "                                names=green_schema_2015_h2_2016_h1.split(','))\n",
    "    green3['dropoff_taxizone_id'] = -1.0\n",
    "    green3['pickup_taxizone_id'] = -1.0\n",
    "\n",
    "    # july 2016 or later dataframe\n",
    "    green4 = dask_cudf.read_csv(green_glob_2016_h2_plus, \n",
    "                                header=0,\n",
    "                                na_values=[\"NA\"],\n",
    "                                parse_dates=[1, 2],\n",
    "                                infer_datetime_format=True,\n",
    "                                dtype=dtype_list,\n",
    "                                names=green_schema_2016_h2_plus.split(','))\n",
    "    green4['dropoff_latitude'] = 0.0\n",
    "    green4['dropoff_longitude'] = 0.0\n",
    "    green4['pickup_latitude'] = 0.0\n",
    "    green4['pickup_longitude'] = 0.0\n",
    "    green4 = green4.drop(['junk1', 'junk2'], axis=1)\n",
    "\n",
    "    # combine dataframes\n",
    "    green = dask_cudf.concat([green1[sorted(green1.columns)],\n",
    "                              green2[sorted(green1.columns)],\n",
    "                              green3[sorted(green1.columns)],\n",
    "                              green4[sorted(green1.columns)]]\n",
    "                            )\n",
    "    for field in list(green.columns):\n",
    "        if field in dtype_list:\n",
    "            green[field] = green[field].astype(dtype_list[field])\n",
    "\n",
    "    green['trip_type'] = 'green'\n",
    "\n",
    "    return green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yellow():\n",
    "    # tag file paths to data and column names by schema (x < 2015, 2015 <= x <= 2016.5, 2016.5 < x)\n",
    "    yellow_schema_pre_2015 = \"vendor_id,pickup_datetime,dropoff_datetime,passenger_count,trip_distance,pickup_longitude,pickup_latitude,rate_code_id,store_and_fwd_flag,dropoff_longitude,dropoff_latitude,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,total_amount\"\n",
    "    yellow_glob_pre_2015 = glob(os.path.join(config['taxi_raw_data_path'], 'yellow_tripdata_201[0-4]*.csv')) + glob(\n",
    "                                os.path.join(config['taxi_raw_data_path'], 'yellow_tripdata_2009*.csv'))\n",
    "    yellow_schema_2015_2016_h1 = \"vendor_id,pickup_datetime,dropoff_datetime,passenger_count,trip_distance,pickup_longitude,pickup_latitude,rate_code_id,store_and_fwd_flag,dropoff_longitude,dropoff_latitude,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount\"\n",
    "    yellow_glob_2015_2016_h1 = glob(os.path.join(config['taxi_raw_data_path'], 'yellow_tripdata_2015*.csv')) + glob(\n",
    "                                    os.path.join(config['taxi_raw_data_path'], 'yellow_tripdata_2016-0[1-6].csv'))\n",
    "    yellow_schema_2016_h2_plus = \"vendor_id,pickup_datetime,dropoff_datetime,passenger_count,trip_distance,rate_code_id,store_and_fwd_flag,pickup_taxizone_id,dropoff_taxizone_id,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount,junk1,junk2\"\n",
    "    yellow_glob_2016_h2_plus = glob(os.path.join(config['taxi_raw_data_path'], 'yellow_tripdata_2016-0[7-9].csv')) + glob(\n",
    "                                    os.path.join(config['taxi_raw_data_path'], 'yellow_tripdata_2016-1[0-2].csv')) + glob(\n",
    "                                    os.path.join(config['taxi_raw_data_path'], 'yellow_tripdata_201[7-9]*.csv'))\n",
    "\n",
    "    # create pre 2015 dataframe\n",
    "    yellow1 = dask_cudf.read_csv(yellow_glob_pre_2015, \n",
    "                                 header=0,\n",
    "                                 na_values=[\"NA\"],\n",
    "                                 parse_dates=[1, 2],\n",
    "                                 infer_datetime_format=True,\n",
    "                                 dtype=dtype_list,\n",
    "                                 names=yellow_schema_pre_2015.split(',')\n",
    "                                )\n",
    "    yellow1['dropoff_taxizone_id'] = -1.0\n",
    "    yellow1['pickup_taxizone_id'] = -1.0\n",
    "    yellow1['ehail_fee'] = np.nan\n",
    "    yellow1['improvement_surcharge'] = np.nan\n",
    "    yellow1['improvement_surcharge'] = yellow1['improvement_surcharge'].astype('float32')\n",
    "    yellow1['trip_type'] = -1.0\n",
    "    \n",
    "    # create january 2015 - june 2016 dataframe\n",
    "    yellow2 = dask_cudf.read_csv(yellow_glob_2015_2016_h1, \n",
    "                                 header=0,\n",
    "                                 na_values=[\"NA\"],\n",
    "                                 parse_dates=[1, 2],\n",
    "                                 infer_datetime_format=True,\n",
    "                                 dtype=dtype_list,\n",
    "                                 names=yellow_schema_2015_2016_h1.split(',')\n",
    "                                )\n",
    "    yellow2['dropoff_taxizone_id'] = -1.0\n",
    "    yellow2['pickup_taxizone_id'] = -1.0\n",
    "    yellow2['ehail_fee'] = np.nan\n",
    "    yellow2['trip_type'] = -1.0\n",
    "\n",
    "    # create post june 2016 dataframe\n",
    "    yellow3 = dask_cudf.read_csv(yellow_glob_2016_h2_plus, \n",
    "                                 header=0,\n",
    "                                 na_values=[\"NA\"],\n",
    "                                 parse_dates=[1, 2],\n",
    "                                 infer_datetime_format=True,\n",
    "                                 dtype=dtype_list,\n",
    "                                 names=yellow_schema_2016_h2_plus.split(',')\n",
    "                                )\n",
    "    yellow3['dropoff_latitude'] = 0.0\n",
    "    yellow3['dropoff_longitude'] = 0.0\n",
    "    yellow3['pickup_latitude'] = 0.0\n",
    "    yellow3['pickup_longitude'] = 0.0\n",
    "    yellow3['ehail_fee'] = np.nan\n",
    "    yellow3['trip_type'] = -1.0\n",
    "    yellow3 = yellow3.drop(['junk1', 'junk2'], axis=1)\n",
    "\n",
    "    yellow = dask_cudf.concat([yellow1[sorted(yellow1.columns)], \n",
    "                               yellow2[sorted(yellow1.columns)], \n",
    "                               yellow3[sorted(yellow1.columns)]]\n",
    "                             )\n",
    "    for field in list(yellow.columns):\n",
    "        if field in dtype_list:\n",
    "            yellow[field] = yellow[field].astype(dtype_list[field])\n",
    "\n",
    "    yellow['trip_type'] = 'yellow'\n",
    "\n",
    "    return yellow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber():\n",
    "    uber_schema_2014 = \"pickup_datetime,pickup_latitude,pickup_longitude,junk1\"\n",
    "    uber_glob_2014 = glob(os.path.join(config['uber_raw_data_path'], 'uber*-???14.csv'))\n",
    "\n",
    "    uber1 = dask_cudf.read_csv(uber_glob_2014, \n",
    "                               header=0,\n",
    "                               na_values=[\"NA\"], \n",
    "                               parse_dates=[0,],\n",
    "                               infer_datetime_format = True,\n",
    "                               dtype=dtype_list,\n",
    "                               names=uber_schema_2014.split(',')\n",
    "                              )\n",
    "    uber1 = uber1.drop(['junk1',], axis=1)\n",
    "    uber1 = uber1.assign(pickup_taxizone_id=-1.0)\n",
    "\n",
    "    uber_schema_2015 = \"junk1,pickup_datetime,junk2,pickup_taxizone_id\"\n",
    "    uber_glob_2015 = glob(os.path.join(config['uber_raw_data_path'], 'uber*15.csv'))\n",
    "\n",
    "    uber2 = dask_cudf.read_csv(uber_glob_2015, \n",
    "                        header=0,\n",
    "                        na_values=[\"NA\"], \n",
    "                        parse_dates=[1,],\n",
    "                        infer_datetime_format = True,\n",
    "                        dtype=dtype_list,\n",
    "                        names=uber_schema_2015.split(',')\n",
    "                       )\n",
    "    uber2 = uber2.drop(['junk1', 'junk2'], axis=1)\n",
    "    uber2 = uber2.assign(pickup_latitude=0.0, pickup_longitude=0.0)\n",
    "\n",
    "    uberdf = dask_cudf.concat([uber1[sorted(uber1.columns)], \n",
    "                               uber2[sorted(uber1.columns)]]\n",
    "                             )\n",
    "    for field in dtype_list:\n",
    "        if (field in uberdf.columns):\n",
    "            uberdf[field] = uberdf[field].astype(dtype_list[field])\n",
    "        elif field == 'pickup_datetime':\n",
    "            pass\n",
    "        else:\n",
    "            uberdf[field] = np.nan\n",
    "            uberdf[field] = uberdf[field].astype(dtype_list[field])\n",
    "\n",
    "    uberdf = uberdf.drop(['junk1', 'junk2'], axis=1)\n",
    "\n",
    "#     uberdf['dropoff_datetime'] = np.datetime64(\"1970-01-01 00:00:00\")\n",
    "#     #uberdf = uberdf.repartition(npartitions=20)\n",
    "\n",
    "    uberdf['trip_type'] = 'uber'\n",
    "\n",
    "    uberdf = uberdf[sorted(uberdf.columns)]\n",
    "\n",
    "    return uberdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "green = get_green()\n",
    "yellow = get_yellow()\n",
    "uber = get_uber()\n",
    "\n",
    "all_trips = uber.append(green).append(yellow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip_iterations = list(np.arange(0, 263, 31))\n",
    "pip_iterations.append(263)\n",
    "\n",
    "taxi_zones = cuspatial.read_polygon_shapefile('zones/cu_taxi_zones.shp')\n",
    "\n",
    "def assign_taxi_zones(df, lon_var, lat_var, locid_var):\n",
    "    \"\"\"\n",
    "    Derives Taxi Zones from shapefile.\n",
    "    \n",
    "    This function takes longitude values provided by `lon_var`, and latitude\n",
    "    values provided by `lat_var` in DataFrame `df`, and performs a spatial join\n",
    "    with the NYC taxi_zones shapefile. \n",
    "    \n",
    "    The shapefile is hard coded in, as this function makes a hard assumption of\n",
    "    latitude and longitude coordinates. It also assumes latitude=0.0 and \n",
    "    longitude=0.0 is not a datapoint that can exist in your dataset. Which is \n",
    "    reasonable for a dataset of New York, but a bit edgy for a global dataset.\n",
    "    \n",
    "    Only rows where `df.lon_var`, `df.lat_var` are reasonably near New York,\n",
    "    and `df.locid_var` is set to -1.0 are updated.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : cudf.DataFrame or dask_cudf.DataFrame\n",
    "        DataFrame containing latitudes, longitudes, and location_id columns.\n",
    "    lon_var : string\n",
    "        Name of column in `df` containing longitude values. Invalid values \n",
    "        should be -1.0.\n",
    "    lat_var : string\n",
    "        Name of column in `df` containing latitude values. Invalid values \n",
    "        should be -1.0\n",
    "    locid_var : string\n",
    "        Name of column in `df` containing taxi_zone location ids. Rows with\n",
    "        valid, nonzero values are not overwritten.\n",
    "        \"\"\"\n",
    "    # focus location columns\n",
    "    localdf = df[[lon_var, lat_var, locid_var]].copy()\n",
    "    # localdf = localdf.reset_index()\n",
    "    \n",
    "    # fill missing lat/long values\n",
    "    localdf[lon_var] = localdf[lon_var].fillna(value=0.0)\n",
    "    localdf[lat_var] = localdf[lat_var].fillna(value=0.0)\n",
    "    \n",
    "    # (bool column) is location id missing && do we have lat/long coordinates?\n",
    "    localdf['replace_locid'] = ((localdf[locid_var] == -1.0)\n",
    "                                & (localdf[lon_var] != 0.0)\n",
    "                                & (localdf[lat_var] != 0.0)\n",
    "                               )\n",
    "    \n",
    "    # are there any values to replace?\n",
    "    if (np.any(localdf['replace_locid'])):  # makes ~28.469% faster\n",
    "        # go through zones 31 at a time\n",
    "        for i in range(len(pip_iterations)-1):\n",
    "            # tag 1st and last zone #s\n",
    "            start = pip_iterations[i]\n",
    "            end = pip_iterations[i+1]\n",
    "            # derive taxi zones from coordinates\n",
    "            t_zones = cuspatial.point_in_polygon(localdf[lon_var], \n",
    "                                                 localdf[lat_var], \n",
    "                                                 taxi_zones[0][start:end], \n",
    "                                                 taxi_zones[1], \n",
    "                                                 taxi_zones[2]['x'], \n",
    "                                                 taxi_zones[2]['y'])\n",
    "            # insert taxi zones into location id columns \n",
    "            for j in t_zones.columns:\n",
    "                localdf[locid_var].loc[t_zones[j]] = j\n",
    "            \n",
    "        return localdf[locid_var].astype('float64') \n",
    "\n",
    "    else:\n",
    "        localdf[locid_var] = localdf[locid_var].astype('float64')   \n",
    "        return localdf[locid_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# derive & assign pickup & dropoff taxi zones \n",
    "all_trips['dropoff_taxizone_id'] = all_trips.map_partitions(assign_taxi_zones, \n",
    "                                                            lon_var='dropoff_longitude', \n",
    "                                                            lat_var='dropoff_latitude',\n",
    "                                                            locid_var='dropoff_taxizone_id', \n",
    "                                                            meta=('dropoff_taxizone_id', np.float64))\n",
    "all_trips['pickup_taxizone_id'] = all_trips.map_partitions(assign_taxi_zones, \n",
    "                                                           lon_var='pickup_longitude', \n",
    "                                                           lat_var='pickup_latitude',\n",
    "                                                           locid_var='pickup_taxizone_id', \n",
    "                                                           meta=('pickup_taxizone_id', np.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trips = all_trips[sorted(all_trips.columns)]\n",
    "# all_trips = all_trips.repartition(npartitions=1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_trips = all_trips.map_partitions(lambda x: x.sort_values('pickup_datetime'), \n",
    "                                     meta=all_trips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fieldName in all_trips.columns:\n",
    "    if fieldName in dtype_list:\n",
    "        all_trips[fieldName] = all_trips[fieldName].astype(dtype_list[fieldName])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 17s, sys: 27.7 s, total: 1min 45s\n",
      "Wall time: 1min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "all_trips.to_parquet(os.path.join(config['parquet_output_path'], 'all_trips_unprocessed.parquet'),\n",
    "                     compression='snappy',  # GZIP'\n",
    "                     has_nulls=True,\n",
    "                     object_encoding='json',\n",
    "                     index=False\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BlazingContext ready\n"
     ]
    }
   ],
   "source": [
    "from blazingsql import BlazingContext\n",
    "bc = BlazingContext()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc.create_table('taxi', [f'data/all_trips_unprocessed.parquet/part.{i}.parquet' for i in range(25)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>dropoff_datetime</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>dropoff_taxizone_id</th>\n",
       "      <th>ehail_fee</th>\n",
       "      <th>extra</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>improvement_surcharge</th>\n",
       "      <th>mta_tax</th>\n",
       "      <th>...</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>pickup_taxizone_id</th>\n",
       "      <th>rate_code_id</th>\n",
       "      <th>store_and_fwd_flag</th>\n",
       "      <th>tip_amount</th>\n",
       "      <th>tolls_amount</th>\n",
       "      <th>total_amount</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>trip_type</th>\n",
       "      <th>vendor_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.9932</td>\n",
       "      <td>185.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uber</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.9777</td>\n",
       "      <td>238.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uber</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>78981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.9706</td>\n",
       "      <td>161.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uber</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-74.0060</td>\n",
       "      <td>248.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uber</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>74756</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-73.9846</td>\n",
       "      <td>163.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uber</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407618</th>\n",
       "      <td>139</td>\n",
       "      <td>2018-02-01 00:09:05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.30</td>\n",
       "      <td>3.30</td>\n",
       "      <td>yellow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407619</th>\n",
       "      <td>50798</td>\n",
       "      <td>2018-02-01 00:05:07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.60</td>\n",
       "      <td>1.60</td>\n",
       "      <td>yellow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407620</th>\n",
       "      <td>12630</td>\n",
       "      <td>2018-02-01 00:01:13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>114.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>yellow</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407621</th>\n",
       "      <td>20387</td>\n",
       "      <td>2018-02-01 00:02:30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>234.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.35</td>\n",
       "      <td>0.40</td>\n",
       "      <td>yellow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2407622</th>\n",
       "      <td>58226</td>\n",
       "      <td>2018-02-01 00:20:51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.5</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>230.0</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.30</td>\n",
       "      <td>3.20</td>\n",
       "      <td>yellow</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2407623 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index     dropoff_datetime dropoff_latitude dropoff_longitude  \\\n",
       "0        69553                  NaN              NaN               NaN   \n",
       "1        50011                  NaN              NaN               NaN   \n",
       "2        78981                  NaN              NaN               NaN   \n",
       "3        25675                  NaN              NaN               NaN   \n",
       "4        74756                  NaN              NaN               NaN   \n",
       "...        ...                  ...              ...               ...   \n",
       "2407618    139  2018-02-01 00:09:05              0.0               0.0   \n",
       "2407619  50798  2018-02-01 00:05:07              0.0               0.0   \n",
       "2407620  12630  2018-02-01 00:01:13              0.0               0.0   \n",
       "2407621  20387  2018-02-01 00:02:30              0.0               0.0   \n",
       "2407622  58226  2018-02-01 00:20:51              0.0               0.0   \n",
       "\n",
       "         dropoff_taxizone_id ehail_fee  extra  fare_amount  \\\n",
       "0                        NaN       NaN    NaN          NaN   \n",
       "1                        NaN       NaN    NaN          NaN   \n",
       "2                        NaN       NaN    NaN          NaN   \n",
       "3                        NaN       NaN    NaN          NaN   \n",
       "4                        NaN       NaN    NaN          NaN   \n",
       "...                      ...       ...    ...          ...   \n",
       "2407618                 68.0       NaN    0.5         12.0   \n",
       "2407619                  4.0       NaN    0.5          8.0   \n",
       "2407620                 79.0       NaN    0.5          4.0   \n",
       "2407621                107.0       NaN    0.5          4.0   \n",
       "2407622                224.0       NaN    0.5         16.0   \n",
       "\n",
       "         improvement_surcharge  mta_tax  ... pickup_longitude  \\\n",
       "0                          NaN      NaN  ...         -73.9932   \n",
       "1                          NaN      NaN  ...         -73.9777   \n",
       "2                          NaN      NaN  ...         -73.9706   \n",
       "3                          NaN      NaN  ...         -74.0060   \n",
       "4                          NaN      NaN  ...         -73.9846   \n",
       "...                        ...      ...  ...              ...   \n",
       "2407618                    0.3      0.5  ...           0.0000   \n",
       "2407619                    0.3      0.5  ...           0.0000   \n",
       "2407620                    0.3      0.5  ...           0.0000   \n",
       "2407621                    0.3      0.5  ...           0.0000   \n",
       "2407622                    0.3      0.5  ...           0.0000   \n",
       "\n",
       "         pickup_taxizone_id  rate_code_id store_and_fwd_flag tip_amount  \\\n",
       "0                     185.0           NaN                NaN        NaN   \n",
       "1                     238.0           NaN                NaN        NaN   \n",
       "2                     161.0           NaN                NaN        NaN   \n",
       "3                     248.0           NaN                NaN        NaN   \n",
       "4                     163.0           NaN                NaN        NaN   \n",
       "...                     ...           ...                ...        ...   \n",
       "2407618                87.0             1                  N       0.00   \n",
       "2407619                90.0             1                  N       2.30   \n",
       "2407620               114.0             1                  N       0.00   \n",
       "2407621               234.0             1                  N       1.05   \n",
       "2407622               230.0             1                  N       2.00   \n",
       "\n",
       "         tolls_amount  total_amount  trip_distance  trip_type vendor_id  \n",
       "0                 NaN           NaN            NaN       uber       NaN  \n",
       "1                 NaN           NaN            NaN       uber       NaN  \n",
       "2                 NaN           NaN            NaN       uber       NaN  \n",
       "3                 NaN           NaN            NaN       uber       NaN  \n",
       "4                 NaN           NaN            NaN       uber       NaN  \n",
       "...               ...           ...            ...        ...       ...  \n",
       "2407618           0.0         13.30           3.30     yellow         1  \n",
       "2407619           0.0         11.60           1.60     yellow         1  \n",
       "2407620           0.0          5.30           0.49     yellow         2  \n",
       "2407621           0.0          6.35           0.40     yellow         1  \n",
       "2407622           0.0         19.30           3.20     yellow         1  \n",
       "\n",
       "[2407623 rows x 24 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bc.sql('select * from taxi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pickup_taxizone_id</th>\n",
       "      <th>dropoff_taxizone_id</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>fare_amount</th>\n",
       "      <th>tax</th>\n",
       "      <th>tip_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>200.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>763</th>\n",
       "      <td>200.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>2.20</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>200.0</td>\n",
       "      <td>236.0</td>\n",
       "      <td>7.20</td>\n",
       "      <td>1</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>765</th>\n",
       "      <td>200.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>766</th>\n",
       "      <td>200.0</td>\n",
       "      <td>127.0</td>\n",
       "      <td>2.87</td>\n",
       "      <td>3</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>767</th>\n",
       "      <td>200.0</td>\n",
       "      <td>243.0</td>\n",
       "      <td>3.42</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.84</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pickup_taxizone_id  dropoff_taxizone_id  trip_distance passenger_count  \\\n",
       "0                 200.0                  NaN            NaN             NaN   \n",
       "1                 200.0                  NaN            NaN             NaN   \n",
       "2                 200.0                  NaN            NaN             NaN   \n",
       "3                 200.0                  NaN            NaN             NaN   \n",
       "4                 200.0                  NaN            NaN             NaN   \n",
       "..                  ...                  ...            ...             ...   \n",
       "763               200.0                242.0           2.20               1   \n",
       "764               200.0                236.0           7.20               1   \n",
       "765               200.0                200.0           0.98               2   \n",
       "766               200.0                127.0           2.87               3   \n",
       "767               200.0                243.0           3.42               1   \n",
       "\n",
       "     fare_amount   tax  tip_amount  \n",
       "0            NaN   NaN         NaN  \n",
       "1            NaN   NaN         NaN  \n",
       "2            NaN   NaN         NaN  \n",
       "3            NaN   NaN         NaN  \n",
       "4            NaN   NaN         NaN  \n",
       "..           ...   ...         ...  \n",
       "763         10.0  1.30        0.00  \n",
       "764         23.0  0.80        0.00  \n",
       "765          6.0  2.16        1.36  \n",
       "766         16.0  0.80        0.00  \n",
       "767         12.0  3.84        0.00  \n",
       "\n",
       "[768 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = 'pickup_taxizone_id, dropoff_taxizone_id, trip_distance, passenger_count, fare_amount, total_amount - fare_amount as tax, tip_amount'\n",
    "bc.sql(f'select {cols} from taxi where pickup_taxizone_id = 200 and year(cast(pickup_datetime as timestamp)) between 2014 and 2018')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAPIDS Stable",
   "language": "python",
   "name": "rapids-stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
